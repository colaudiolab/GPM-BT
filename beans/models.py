import argparse

import torch
import torch.nn as nn
import torchvision


class ResNetClassifier(nn.Module):
    def __init__(self, model_type, pretrained=False, num_classes=None, multi_label=False):
        super().__init__()

        if model_type.startswith('resnet50'):
            # weights = torchvision.models.ResNet50_Weights.DEFAULT
            # self.resnet = torchvision.models.resnet50(weights=weights if pretrained else None)
            self.resnet = torchvision.models.resnet50(pretrained = pretrained)
        elif model_type.startswith('resnet152'):
            # weights = torchvision.models.ResNet152_Weights.DEFAULT
            # self.resnet = torchvision.models.resnet152(weights=weights if pretrained else None)
            self.resnet = torchvision.models.resnet152(pretrained=pretrained)
        elif model_type.startswith('resnet18'):
            # weights = torchvision.models.ResNet18_Weights.DEFAULT
            # self.resnet = torchvision.models.resnet18(weights=weights if pretrained else None)
            self.resnet = torchvision.models.resnet18(pretrained=pretrained)
        else:
            assert False

        self.linear = nn.Linear(in_features=1000, out_features=num_classes)

        if multi_label:
            self.loss_func = nn.BCEWithLogitsLoss()
        else:
            self.loss_func = nn.CrossEntropyLoss()

    def forward(self, x, y=None):
        x = x.unsqueeze(1)      # (B, F, L) -> (B, 1, F, L)
        x = x.repeat(1, 3, 1, 1)    # -> (B, 3, F, L)
        x /= x.max()            # normalize to [0, 1]
        # x = self.transform(x)

        x = self.resnet(x)
        logits = self.linear(x)
        loss = None
        if y is not None:
            loss = self.loss_func(logits, y)

        return loss, logits


class VGGishClassifier(nn.Module):
    def __init__(self, sample_rate, num_classes=None, multi_label=False):
        super().__init__()

        self.vggish = torch.hub.load('harritaylor/torchvggish', 'vggish')
        self.vggish.postprocess = False
        self.vggish.preprocess = False

        self.linear = nn.Linear(in_features=128, out_features=num_classes)

        if multi_label:
            self.loss_func = nn.BCEWithLogitsLoss()
        else:
            self.loss_func = nn.CrossEntropyLoss()

        self.sample_rate = sample_rate

    def forward(self, x, y=None):
        batch_size = x.shape[0]
        x = x.reshape(-1, x.shape[2], x.shape[3], x.shape[4])
        out = self.vggish(x)
        out = out.reshape(batch_size, -1, out.shape[1])
        outs = out.mean(dim=1)
        logits = self.linear(outs)

        loss = None
        if y is not None:
            loss = self.loss_func(logits, y)

        return loss, logits

